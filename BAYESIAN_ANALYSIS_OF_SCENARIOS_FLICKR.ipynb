{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNi6Qhh92NGZr6aywb5ewXb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qItSRCXBKGrp","executionInfo":{"status":"ok","timestamp":1712218286817,"user_tz":-120,"elapsed":41977,"user":{"displayName":"Sushant","userId":"01539954029328098546"}},"outputId":"23afb9af-5e08-4740-8873-498c5856005a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n","Cloning into 'pycocoevalcap'...\n","remote: Enumerating objects: 821, done.\u001b[K\n","remote: Counting objects: 100% (24/24), done.\u001b[K\n","remote: Compressing objects: 100% (20/20), done.\u001b[K\n","remote: Total 821 (delta 5), reused 19 (delta 4), pack-reused 797\u001b[K\n","Receiving objects: 100% (821/821), 130.06 MiB | 8.93 MiB/s, done.\n","Resolving deltas: 100% (424/424), done.\n","Updating files: 100% (40/40), done.\n"]}],"source":["!pip install nltk rouge\n","!git clone https://github.com/salaniz/pycocoevalcap\n"]},{"cell_type":"code","source":["from google.colab import drive\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmZtQ-ZAKP1h","executionInfo":{"status":"ok","timestamp":1712218312107,"user_tz":-120,"elapsed":25299,"user":{"displayName":"Sushant","userId":"01539954029328098546"}},"outputId":"31b97519-132d-4cbc-9eb4-75624938adc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import json\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from random import shuffle\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","def load_json(file_path):\n","    with open(file_path, 'r') as f:\n","        return json.load(f)\n","\n","def calculate_corpus_bleu(references, candidate):\n","    references_tokenized = [[word_tokenize(ref.lower()) for ref in references]]\n","    candidate_tokenized = [word_tokenize(candidate.lower())]\n","    smoothing_function = SmoothingFunction().method1\n","    return corpus_bleu(references_tokenized, candidate_tokenized, smoothing_function=smoothing_function)\n","\n","def calculate_cosine_similarity(text1, text2):\n","    vectorizer = TfidfVectorizer()\n","    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n","    return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n","\n","def calculate_average_cosine_similarity(generated_caption, original_captions):\n","    similarities = [calculate_cosine_similarity(generated_caption, original) for original in original_captions]\n","    return sum(similarities) / len(similarities)\n","\n","# Function to calculate the average of a list\n","def avg(lst):\n","    return sum(lst) / len(lst) if lst else 0\n","\n","# Load the entire dataset\n","data = load_json('/content/drive/MyDrive/MasterThesis/flickr8k_dataset/Scenario1_distilbart_with_all_similarities_only_2_flickr.json')\n","\n","# Shuffle and split the dataset into training (80%) and testing (20%) segments\n","items = list(data.values())\n","shuffle(items)\n","split_index = int(0.8 * len(items))\n","data_train = items[:split_index]\n","data_test = items[split_index:]\n","\n","# Initialize counters for calculating priors based on cosine similarity\n","better_count_train = {'blip': 0, 'gpt2': 0}\n","\n","# Calculate priors based on average cosine similarity in training data\n","for item in data_train:\n","    original_captions = [' '.join(item['original_coco_captions'])]  # Combine all original captions into a single text for simplicity\n","    cos_similarities = {model: calculate_average_cosine_similarity(item['generated_captions'][model], original_captions) for model in ['gpt2', 'blip']}\n","    better_model = max(cos_similarities, key=cos_similarities.get)\n","    better_count_train[better_model] += 1\n","\n","total_instances_train = sum(better_count_train.values())\n","prior_gpt = better_count_train['gpt2'] / total_instances_train\n","prior_blip = better_count_train['blip'] / total_instances_train\n","\n","# Calculate likelihoods using testing data\n","bleu_scores_test = {'blip': [], 'gpt2': []}\n","for item in data_test:\n","    original_captions = item['original_coco_captions']\n","    for model in ['gpt2', 'blip']:\n","        bleu_score = calculate_corpus_bleu(original_captions, item['generated_captions'][model])\n","        bleu_scores_test[model].append(bleu_score)\n","\n","likelihood_gpt = avg(bleu_scores_test['gpt2'])\n","likelihood_blip = avg(bleu_scores_test['blip'])\n","\n","# Calculate Marginal Likelihood (Evidence)\n","marginal_likelihood = likelihood_gpt * prior_gpt + likelihood_blip * prior_blip\n","\n","# Calculate Posterior probabilities\n","posterior_gpt = (likelihood_gpt * prior_gpt) / marginal_likelihood\n","posterior_blip = (likelihood_blip * prior_blip) / marginal_likelihood\n","\n","print(f\"Prior for GPT: {prior_gpt:.4f}, Prior for BLIP: {prior_blip:.4f}\")\n","print(f\"Likelihood (Average BLEU) for GPT on test data: {likelihood_gpt:.4f}\")\n","print(f\"Likelihood (Average BLEU) for BLIP on test data: {likelihood_blip:.4f}\")\n","print(f\"Marginal Likelihood (Evidence): {marginal_likelihood:.4f}\")\n","print(f\"Posterior for GPT: {posterior_gpt:.4f}\")\n","print(f\"Posterior for BLIP: {posterior_blip:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JT9z7Q92Kx3W","executionInfo":{"status":"ok","timestamp":1712218507509,"user_tz":-120,"elapsed":9104,"user":{"displayName":"Sushant","userId":"01539954029328098546"}},"outputId":"e4bd9e8a-44c7-40f3-f540-c94a8fa4edfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Prior for GPT: 0.3136, Prior for BLIP: 0.6864\n","Likelihood (Average BLEU) for GPT on test data: 0.1555\n","Likelihood (Average BLEU) for BLIP on test data: 0.1772\n","Marginal Likelihood (Evidence): 0.1704\n","Posterior for GPT: 0.2862\n","Posterior for BLIP: 0.7138\n"]}]},{"cell_type":"code","source":["import json\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from random import shuffle\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","def load_json(file_path):\n","    with open(file_path, 'r') as f:\n","        return json.load(f)\n","\n","def calculate_corpus_bleu(references, candidate):\n","    references_tokenized = [[word_tokenize(ref.lower()) for ref in references]]\n","    candidate_tokenized = [word_tokenize(candidate.lower())]\n","    smoothing_function = SmoothingFunction().method1\n","    return corpus_bleu(references_tokenized, candidate_tokenized, smoothing_function=smoothing_function)\n","\n","def calculate_cosine_similarity(text1, text2):\n","    vectorizer = TfidfVectorizer()\n","    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n","    return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n","\n","def calculate_average_cosine_similarity(generated_caption, original_captions):\n","    similarities = [calculate_cosine_similarity(generated_caption, original) for original in original_captions]\n","    return sum(similarities) / len(similarities)\n","\n","# Function to calculate the average of a list\n","def avg(lst):\n","    return sum(lst) / len(lst) if lst else 0\n","\n","# Load the entire dataset\n","data = load_json('/content/drive/MyDrive/MasterThesis/flickr8k_dataset/Scenario2_distilbart_with_all_similarities_only_2_flickr.json')\n","\n","# Shuffle and split the dataset into training (80%) and testing (20%) segments\n","items = list(data.values())\n","shuffle(items)\n","split_index = int(0.8 * len(items))\n","data_train = items[:split_index]\n","data_test = items[split_index:]\n","\n","# Initialize counters for calculating priors based on cosine similarity\n","better_count_train = {'blip': 0, 'gpt2': 0}\n","\n","# Calculate priors based on average cosine similarity in training data\n","for item in data_train:\n","    original_captions = [' '.join(item['original_coco_captions'])]  # Combine all original captions into a single text for simplicity\n","    cos_similarities = {model: calculate_average_cosine_similarity(item['generated_captions'][model], original_captions) for model in ['gpt2', 'blip']}\n","    better_model = max(cos_similarities, key=cos_similarities.get)\n","    better_count_train[better_model] += 1\n","\n","total_instances_train = sum(better_count_train.values())\n","prior_gpt = better_count_train['gpt2'] / total_instances_train\n","prior_blip = better_count_train['blip'] / total_instances_train\n","\n","# Calculate likelihoods using testing data\n","bleu_scores_test = {'blip': [], 'gpt2': []}\n","for item in data_test:\n","    original_captions = item['original_coco_captions']\n","    for model in ['gpt2', 'blip']:\n","        bleu_score = calculate_corpus_bleu(original_captions, item['generated_captions'][model])\n","        bleu_scores_test[model].append(bleu_score)\n","\n","likelihood_gpt = avg(bleu_scores_test['gpt2'])\n","likelihood_blip = avg(bleu_scores_test['blip'])\n","\n","# Calculate Marginal Likelihood (Evidence)\n","marginal_likelihood = likelihood_gpt * prior_gpt + likelihood_blip * prior_blip\n","\n","# Calculate Posterior probabilities\n","posterior_gpt = (likelihood_gpt * prior_gpt) / marginal_likelihood\n","posterior_blip = (likelihood_blip * prior_blip) / marginal_likelihood\n","\n","print(f\"Prior for GPT: {prior_gpt:.4f}, Prior for BLIP: {prior_blip:.4f}\")\n","print(f\"Likelihood (Average BLEU) for GPT on test data: {likelihood_gpt:.4f}\")\n","print(f\"Likelihood (Average BLEU) for BLIP on test data: {likelihood_blip:.4f}\")\n","print(f\"Marginal Likelihood (Evidence): {marginal_likelihood:.4f}\")\n","print(f\"Posterior for GPT: {posterior_gpt:.4f}\")\n","print(f\"Posterior for BLIP: {posterior_blip:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIHI_uXPLOL4","executionInfo":{"status":"ok","timestamp":1712218519548,"user_tz":-120,"elapsed":8610,"user":{"displayName":"Sushant","userId":"01539954029328098546"}},"outputId":"7bf43f9b-e14f-432f-a489-ae1828414dfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Prior for GPT: 0.3068, Prior for BLIP: 0.6932\n","Likelihood (Average BLEU) for GPT on test data: 0.1538\n","Likelihood (Average BLEU) for BLIP on test data: 0.1826\n","Marginal Likelihood (Evidence): 0.1737\n","Posterior for GPT: 0.2715\n","Posterior for BLIP: 0.7285\n"]}]}]}